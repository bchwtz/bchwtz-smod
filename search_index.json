[["index.html", "Statistical Modeling Chapter 1 Prerequisites", " Statistical Modeling Benjamin Buchwitz 2021-01-11 Chapter 1 Prerequisites This repo contains course materials. "],["factor-analysis.html", "Chapter 2 Factor Analysis 2.1 Foundations 2.2 Estimation 2.3 Rotation 2.4 Basic Factor Analysis in R Exercises", " Chapter 2 Factor Analysis Statistically speaking the main goal of factor analysis is to describe the covariance structure among many variables in terms of a few underlying, but unobservable random quantities, called factors. This usually happens by assuming that the supposed variables can be organized into (contextually meaningful) groups. The variables in a given group are assumed to be highly correlated and thus represent or are related to a latent construct. While the correlation within a group of variables is high, the correlation between different groups should be low. Following that argumentation it may be possible to condense the information from multiple observed variables within a group into a single unobserved factor variable. While Explanatory Factor Analysis (EFA) aims at finding the mentioned groups Confirmatory Factor Analysis (CFA) aims at confirming an a priori hypothesized variable grouping constellation. While EFA and CFA serve different purposes when doing research, their foundation, especially the model formulation, the estimation and the derivation of quantities of interest is highly comparable and will be presented below. 2.1 Foundations \\[ X_1 - \\mu_1 = l_{11} F_1 + l_{12} F_2 + \\ldots + l_{1m} F_m + \\epsilon_1 \\\\ X_2 - \\mu_2 = l_{21} F_1 + l_{22} F_2 + \\ldots + l_{2m} F_m + \\epsilon_2 \\\\ \\vdots \\\\ X_p - \\mu_p = l_{p1} F_1 + l_{p2} F_2 + \\ldots + l_{pm} F_m + \\epsilon_p \\] Although the equations above seem to be related to multiple regression equations the fact that all quantities on the right hand side are unobseved (in fact only \\(X\\) is observed) distinguishes this factor model from regression problems. The factor analysis model can also be written in matrix notation, which allows for easier derivation of some of the following procedures and thus should be considered valuable as well. \\[ \\underset{p \\times 1}{\\boldsymbol X} = \\underset{p \\times 1}{\\boldsymbol \\mu} + \\underset{p \\times m}{\\boldsymbol L} \\; \\underset{m \\times p}{\\boldsymbol F} + \\underset{p \\times 1}{\\boldsymbol \\epsilon} \\] \\[ \\underset{p \\times 1}{\\boldsymbol X - \\boldsymbol \\mu} = \\underset{p \\times m}{\\boldsymbol L} \\; \\underset{m \\times p}{\\boldsymbol F} + \\underset{p \\times 1}{\\boldsymbol \\epsilon} \\] \\[ \\boldsymbol \\Sigma = Cov(\\boldsymbol X) = \\underset{\\;\\\\Communality}{\\boldsymbol L \\boldsymbol L^T} + \\underset{\\;\\\\Uniqueness}{\\boldsymbol \\Psi} \\] 2.2 Estimation Work in Progress … 2.2.1 Principal Component Method 2.2.2 Principal Factor Solution 2.2.3 Maximum Likelihood Estimation 2.3 Rotation Work in Progress … 2.4 Basic Factor Analysis in R In R there are multiple implementations of factor analysis available. Each model variant and each implementation comes with its own strengths and drawbacks. A good starting point is the factanal() function that comes with the preinstalled stats package. However, more elaborate and flexible approaches are available for download (e.g. in the psych package). In this part we are focusing on the the factor analysis procedure that is implemented in the factanal() function, which performs maximum-likelihood factor analysis on a covariance, correlation or data matrix. For using factanal() four arguments are essential x to input the data, factors to specify the number of factors that should be used, scores to specify the method used to calculate the factor scores and rotation to specify the method for orthogonal or oblique rotation. factanal(x, # Data factors, # Number of factors scores, # Method to calculate factor scores rotation) # Method for rotation While x and factors must be specified by the user the arguments scores and rotation use default values. Factor scores could be calculated either using Thompsons method (scores = \"regression\"), based on Bartlett’s weighted least-squares approach (scores = \"Bartlett\") or not calculated at all (defaul: scores = \"none\"). Applying factor rotation can either be done using the default Varimax option (rotation = \"varimax\") for orthogonal transformation or using rotation = \"Bartlett\" for an oblique transformation. Alternatively results can be obtained without applying a transformation using rotation = \"none\". 2.4.1 Data Preparation and Description Lets get our hands dirty and apply what we learned. The following code loads some data that results from a questionnaire with 50 questions. q &lt;- readRDS(&quot;data/fa_questions.rds&quot;) # Questions asked d &lt;- readRDS(&quot;data/fa_sample.rds&quot;) # Response data The variable q contains the questions from the questionnaire (50 items) while d contains the actual responses. Respondents hat the option to answer each question using a 5-point Likert-Scale, that was labeled 1=Disagree, 3=Neutral, 5=Agree. However, the data is not pre-processed and needs to be thoroughly investigated and potentially cleaned up before it can be used for analytic procedures. head(q, n=6) # Show first 6 rows from the dataframe ## Q coding question ## 1 Q01 P I feel comfortable around people. ## 2 Q02 P I have excellent ideas. ## 3 Q03 N I insult people. ## 4 Q04 P I am the life of the party. ## 5 Q05 N I do not have a good imagination. ## 6 Q06 P I sympathize with others&#39; feelings. The object q contains three variables (columns), the question ID Q, an indication if the question is positively (coding == \"P\") or negatively (coding == \"N\") formulated and the actual formulation of the item question. The responses are saved in object d. head(d, n=6) ## Q04 Q39 Q01 Q34 Q23 Q43 Q14 Q18 Q33 Q21 Q41 Q10 Q07 Q09 Q15 Q40 Q25 Q47 Q12 ## 1 2 3 3 3 3 3 4 3 3 4 4 2 5 2 4 4 4 4 4 ## 2 4 2 3 3 4 2 4 2 4 4 3 4 5 3 4 4 3 4 4 ## 3 3 4 4 3 3 2 3 3 3 3 2 4 4 3 2 3 3 3 4 ## 4 1 3 3 2 4 2 2 2 5 3 2 2 5 1 4 3 5 4 4 ## 5 1 5 1 2 2 1 3 2 4 5 4 2 5 3 3 4 4 3 4 ## 6 1 5 4 5 3 2 1 5 2 5 3 3 5 1 4 3 4 4 2 ## Q36 Q48 Q20 Q03 Q06 Q49 Q26 Q27 Q31 Q29 Q22 Q32 Q24 Q08 Q35 Q37 Q38 Q45 Q19 ## 1 5 2 4 1 4 2 4 2 3 4 4 4 3 4 3 3 4 4 2 ## 2 3 5 4 3 4 2 4 2 4 4 3 4 5 4 4 2 5 1 3 ## 3 3 1 4 2 4 3 3 2 4 3 3 2 2 4 2 4 3 3 2 ## 4 4 2 4 2 4 1 5 2 4 4 4 4 1 4 1 4 1 4 2 ## 5 3 4 4 3 4 2 5 2 4 5 3 5 2 5 1 4 1 4 4 ## 6 4 1 4 2 5 2 5 3 4 4 3 2 4 4 3 3 2 4 2 ## Q42 Q46 Q28 Q13 Q44 Q16 Q02 Q05 Q11 Q50 Q17 Q30 IPC testelapse country ## 1 4 4 4 2 5 2 4 2 4 5 4 4 1 97 DE ## 2 2 3 4 3 4 2 3 4 3 4 4 4 1 162 DE ## 3 3 4 5 1 4 2 4 2 4 2 4 4 1 428 DE ## 4 4 4 5 1 5 1 4 2 5 5 5 3 1 156 DE ## 5 5 5 4 1 5 1 5 1 5 5 3 5 2 221 DE ## 6 3 3 5 2 3 3 3 3 5 5 4 4 1 140 DE dim(d) # Dimensions of the data matrix ## [1] 14095 53 In total we have 14095 observations and 53 variables in the dataframe. The first 50 columns represent the responses to the items introduced above. The remaining three variables (IPC, testelapse, country) provide metadata and some technical information, which can be used to perform plausibility checks and cleanup the data. IPC: Is an abbreviation for IP (Internet Protocol Adress) Count and lists the number of records from the user’s IP address in the dataset. For max cleanliness is is recommended to only use records where this value is 1. It should, however, be noted that high values can have multiple causes and do no necessarily represent abusive usage of the survey service. They can be because of shared networks (e.g. entire universities) or multiple submissions. testelapse: Is the time in seconds spent on the page with the survey questions. country: Indicates the country of the responded, but is determined by technical information and was not asked as a question. 50 Items - Click to expand! rnorm(5) ## [1] 1.4513333 -0.8950159 -0.8152918 -0.2511007 -0.7293953 #kable_paper(kbl(items), &quot;hover&quot;, full_width = F) d_cleaned &lt;- na.omit(d) # Remove rows with missing values. d_small &lt;- d_cleaned[ ,1:6] 2.4.2 Selecting numbers of Factors # Calculate Correlation Matrix, Eigenvalues &amp; Proportion of Variance R &lt;- cor(d_small) eigval &lt;- eigen(R)$values proptotvar &lt;- eigval / sum(eigval) # Screeplot plot(eigval, type = &quot;b&quot;, ylab = &quot;Eigenvalue&quot;, xlab=&quot;Index&quot;, xaxt=&quot;n&quot;) axis(1, at=1:length(eigval)) abline(h=1, lty = &quot;dotted&quot;, col=&quot;red&quot;) df &lt;- data.frame(Eigenvalue = eigval, Var=proptotvar, sumVar=cumsum(proptotvar)) knitr::kable(df, digits=4, booktabs=T) Eigenvalue Var sumVar 3.5200 0.5867 0.5867 0.7488 0.1248 0.7115 0.5207 0.0868 0.7983 0.4586 0.0764 0.8747 0.4120 0.0687 0.9434 0.3399 0.0566 1.0000 2.4.3 Applying Factor Analysis fa_none &lt;- factanal(d_small , factors = 2, rotation = &quot;none&quot;) fa_varimax &lt;- factanal(d_small , factors = 2, rotation = &quot;varimax&quot;) fa_promax &lt;- factanal(d_small, factors = 2, rotation = &quot;promax&quot;) par(mfrow = c(1,3)) plot(fa_none$loadings[,1], fa_none$loadings[,2], xlab = &quot;Factor 1&quot;, ylab = &quot;Factor 2&quot;, ylim = c(-1,1), xlim = c(-1,1), main = &quot;No rotation&quot;) abline(h = 0, v = 0, col=&quot;darkgrey&quot;) plot(fa_varimax$loadings[,1], fa_varimax$loadings[,2], xlab = &quot;Factor 1&quot;, ylab = &quot;Factor 2&quot;, ylim = c(-1,1), xlim = c(-1,1), main = &quot;Varimax rotation&quot;) text(fa_varimax$loadings[,1]-0.08, fa_varimax$loadings[,2]+0.08, colnames(d_small), col=&quot;blue&quot;) abline(h = 0, v = 0, col=&quot;darkgrey&quot;) plot(fa_promax$loadings[,1], fa_promax$loadings[,2], xlab = &quot;Factor 1&quot;, ylab = &quot;Factor 2&quot;, ylim = c(-1,1), xlim = c(-1,1), main = &quot;Promax rotation&quot;) abline(h = 0, v = 0, col=&quot;darkgrey&quot;) 2.4.4 Interpreting the Factors Exercises ski &lt;- data.frame(skiers = paste0(&quot;S&quot;, c(1:5)), cost = c(32, 61, 59, 36, 62), lift = c(64, 37, 40, 62, 46), depth = c(65, 62, 45, 34, 43), powder = c(67, 65, 43, 35, 40)) "],["system-info.html", "Chapter 3 System Info", " Chapter 3 System Info Sys.time() ## [1] &quot;2021-01-11 22:47:50 UTC&quot; sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] kableExtra_1.3.1 knitr_1.30 ## ## loaded via a namespace (and not attached): ## [1] rstudioapi_0.13 xml2_1.3.2 magrittr_2.0.1 rvest_0.3.6 ## [5] munsell_0.5.0 colorspace_2.0-0 viridisLite_0.3.0 R6_2.5.0 ## [9] rlang_0.4.10 stringr_1.4.0 httr_1.4.2 highr_0.8 ## [13] tools_4.0.3 webshot_0.5.2 xfun_0.20 htmltools_0.5.0 ## [17] yaml_2.2.1 digest_0.6.27 lifecycle_0.2.0 bookdown_0.21 ## [21] glue_1.4.2 evaluate_0.14 rmarkdown_2.6 stringi_1.5.3 ## [25] compiler_4.0.3 scales_1.1.1 "]]
